{
 "metadata": {
  "name": "",
  "signature": "sha256:7685f3505eccc22c02e2391d5da8fe01f4e66634c4bc6fe960486c00ca808b72"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This file is a editted version of https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py\n",
      "# Use Lasagne for digit recognition using  MNIST dataset.\n",
      "import os\n",
      "import numpy as np\n",
      "import sys\n",
      "import time\n",
      "import theano\n",
      "import theano.tensor as T\n",
      "import lasagne\n",
      "from lasagne.layers.dnn import Conv2DDNNLayer as Conv2DLayer\n",
      "from lasagne.layers.dnn import MaxPool2DDNNLayer as MaxPool2DLayer\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using gpu device 0: GeForce GT 650M (CNMeM is disabled, cuDNN 5005)\n",
        "/Users/jiajunshen/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/Theano-0.9.0.dev1-py2.7.egg/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
        "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_cnn(input_var=None):\n",
      "\n",
      "    # Input layer, as usual:\n",
      "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
      "                                        input_var=input_var)\n",
      "    # This time we do not apply input dropout, as it tends to work less well\n",
      "    # for convolutional layers.\n",
      "\n",
      "    # Convolutional layer with 32 kernels of size 5x5. Strided and padded\n",
      "    # convolutions are supported as well; see the docstring.\n",
      "    network = Conv2DLayer(\n",
      "            network, num_filters=32, filter_size=(5, 5),\n",
      "            #nonlinearity=lasagne.nonlinearities.sigmoid,\n",
      "            nonlinearity=lasagne.nonlinearities.rectify,\n",
      "            W=lasagne.init.GlorotUniform())\n",
      "    # Expert note: Lasagne provides alternative convolutional layers that\n",
      "    # override Theano's choice of which implementation to use; for details\n",
      "    # please see http://lasagne.readthedocs.org/en/latest/user/tutorial.html.\n",
      "\n",
      "    # Max-pooling layer of factor 2 in both dimensions:\n",
      "    network = MaxPool2DLayer(network, pool_size=(2, 2))\n",
      "\n",
      "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
      "    network = Conv2DLayer(\n",
      "            network, num_filters=32, filter_size=(5, 5),\n",
      "            nonlinearity=lasagne.nonlinearities.rectify,\n",
      "            W = lasagne.init.GlorotUniform()\n",
      "            #nonlinearity=lasagne.nonlinearities.sigmoid\n",
      "            )\n",
      "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
      "    \n",
      "    network_middle_output = lasagne.layers.ReshapeLayer(network, shape = (([0], 2048)))\n",
      "\n",
      "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
      "    network = lasagne.layers.DenseLayer(\n",
      "            lasagne.layers.dropout(network, p=.5),\n",
      "            #network,\n",
      "            num_units=256,\n",
      "            #nonlinearity=lasagne.nonlinearities.sigmoid\n",
      "            nonlinearity=lasagne.nonlinearities.rectify,\n",
      "            )\n",
      "\n",
      "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
      "    network = lasagne.layers.DenseLayer(\n",
      "            lasagne.layers.dropout(network, p=.5),\n",
      "            #network,\n",
      "            num_units=10,\n",
      "            nonlinearity=lasagne.nonlinearities.softmax)\n",
      "\n",
      "    return network, network_middle_output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_rotation_cnn(input_var=None):\n",
      "\n",
      "    # Input layer, as usual:\n",
      "    network = lasagne.layers.InputLayer(shape=(None, 1, 28, 28),\n",
      "                                        input_var=input_var)\n",
      "    # This time we do not apply input dropout, as it tends to work less well\n",
      "    # for convolutional layers.\n",
      "\n",
      "    # Convolutional layer with 32 kernels of size 5x5. Strided and padded\n",
      "    # convolutions are supported as well; see the docstring.\n",
      "    network = Conv2DLayer(\n",
      "            network, num_filters=32, filter_size=(5, 5),\n",
      "            #nonlinearity=lasagne.nonlinearities.sigmoid,\n",
      "            nonlinearity=lasagne.nonlinearities.rectify,\n",
      "            W=lasagne.init.GlorotUniform())\n",
      "    # Expert note: Lasagne provides alternative convolutional layers that\n",
      "    # override Theano's choice of which implementation to use; for details\n",
      "    # please see http://lasagne.readthedocs.org/en/latest/user/tutorial.html.\n",
      "\n",
      "    # Max-pooling layer of factor 2 in both dimensions:\n",
      "    network = MaxPool2DLayer(network, pool_size=(2, 2))\n",
      "\n",
      "    # Another convolution with 32 5x5 kernels, and another 2x2 pooling:\n",
      "    network = Conv2DLayer(\n",
      "            network, num_filters=32, filter_size=(5, 5),\n",
      "            nonlinearity=lasagne.nonlinearities.rectify,\n",
      "            W = lasagne.init.GlorotUniform()\n",
      "            #nonlinearity=lasagne.nonlinearities.sigmoid\n",
      "            )\n",
      "    network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
      "    \n",
      "    network_middle_output = lasagne.layers.ReshapeLayer(network, shape = (([0], 2048)))\n",
      "\n",
      "    # A fully-connected layer of 256 units with 50% dropout on its inputs:\n",
      "    network = lasagne.layers.DenseLayer(\n",
      "            lasagne.layers.dropout(network, p=.5),\n",
      "            #network,\n",
      "            num_units=256,\n",
      "            #nonlinearity=lasagne.nonlinearities.sigmoid\n",
      "            nonlinearity=lasagne.nonlinearities.rectify,\n",
      "            )\n",
      "\n",
      "    # And, finally, the 10-unit output layer with 50% dropout on its inputs:\n",
      "    network = lasagne.layers.DenseLayer(\n",
      "            lasagne.layers.dropout(network, p=.5),\n",
      "            #network,\n",
      "            num_units=10,\n",
      "            nonlinearity=lasagne.nonlinearities.softmax)\n",
      "\n",
      "    return network, network_middle_output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build up the old network.\n",
      "original_input_var = T.tensor4('original_inputs')\n",
      "target_var = T.tensor4('targets')\n",
      "original_network, original_network_middle = build_cnn(input_var)\n",
      "all_weights = np.load(\"../data/mnist_CNN_params_drop_out.npy\")\n",
      "lasagne.layers.set_all_param_values(original_network, all_weights)\n",
      "rotated_input_var = T.tensor4('rotated_inputs')\n",
      "rotated_network, rotated_network_middle = build_c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}